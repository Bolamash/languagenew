{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdefeeda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in \"C:\\\\Users\\\\Ipaye Bolanle Mas'ud\\\\Documents\\\\Classification\\\\predict\" nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/bolamash/classification/e11bc8cc59cb4bce999838bd8b0ea50f\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating an experiment with your api key\n",
    "from comet_ml import Experiment\n",
    "experiment = Experiment(\n",
    "    api_key = \"XTvxi4t0C4xz1pFbi15s0rvsQ\",\n",
    "    project_name = \"classification\",\n",
    "    workspace = \"bolamash\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53df7646",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Ipaye Bolanle\n",
      "[nltk_data]     Mas'ud\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Ipaye Bolanle\n",
      "[nltk_data]     Mas'ud\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Ipaye Bolanle\n",
      "[nltk_data]     Mas'ud\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "# Libraries for data loading, manipulation and visualisation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.style as style\n",
    "from wordcloud import WordCloud\n",
    "from plotly import graph_objects as go \n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "# Libraries for data preparation and model building\n",
    "from sklearn.utils import resample\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, RidgeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "#nlkt libraries\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import re\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c0b79a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text\n",
       "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
       "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
       "2     eng  the province of kwazulu-natal department of tr...\n",
       "3     nso  o netefatša gore o ba file dilo ka moka tše le...\n",
       "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train_set.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ba6a235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mmasepala, fa maemo a a kgethegileng a letlele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tshivhumbeo tshi fana na ngano dza vhathu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Winste op buitelandse valuta.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text\n",
       "0      1  Mmasepala, fa maemo a a kgethegileng a letlele...\n",
       "1      2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
       "2      3         Tshivhumbeo tshi fana na ngano dza vhathu.\n",
       "3      4  Kube inja nelikati betingevakala kutsi titsini...\n",
       "4      5                      Winste op buitelandse valuta."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('test_set.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5a1fda8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lang_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>tsn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>nbl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index lang_id\n",
       "0      1     tsn\n",
       "1      2     nbl"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = pd.read_csv('sample_submission.csv')\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed6b003c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "lang_id    0\n",
       "text       0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "index    0\n",
       "text     0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Train Dataset')\n",
    "display(train_df.isnull().sum())\n",
    "\n",
    "print('Test Dataset')\n",
    "display(test_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3fe8337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the train dataset: (33000, 2)\n",
      "The shape of the test dataset:  (5682, 2)\n"
     ]
    }
   ],
   "source": [
    "#Check shape of datasets\n",
    "print(f'The shape of the train dataset: {train_df.shape}')\n",
    "print(f'The shape of the test dataset:  {test_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67a046d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33000 entries, 0 to 32999\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   lang_id  33000 non-null  object\n",
      " 1   text     33000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 515.8+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46ee6755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['xho', 'eng', 'nso', 'ven', 'tsn', 'nbl', 'zul', 'ssw', 'tso',\n",
       "       'sot', 'afr'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the unique values in target feature\n",
    "train_df['lang_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37604544",
   "metadata": {},
   "source": [
    "### lang_id description\n",
    "\n",
    "afr - Afrikaans\n",
    "\n",
    "eng - English\n",
    "\n",
    "nbl - isiNdebele\n",
    "\n",
    "nso - Sepedi\n",
    "\n",
    "sot - Sesotho\n",
    "\n",
    "ssw - siSwati\n",
    "\n",
    "tsn - Setswana\n",
    "\n",
    "tso - Xitsonga\n",
    "\n",
    "ven - Tshivenda\n",
    "\n",
    "xho - isiXhosa\n",
    "\n",
    "zul - isiZulu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0fb0538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5599, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select all duplicate rows based on the message column from train dataset\n",
    "duplicate_train_df = train_df[train_df.\n",
    "                    duplicated(['text',\n",
    "                                'lang_id'],\n",
    "                               keep=False)]\n",
    "\n",
    "# View number of duplicate rows\n",
    "duplicate_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56eeb072",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to convert class from numerical to word definition of class for a better visualisation\n",
    "def class_convert(df):\n",
    "    df = train_df.copy()\n",
    "    word_class = []\n",
    "    old_class = df['lang_id']\n",
    "    \n",
    "    for class_id in old_class:\n",
    "        if class_id  == 'zul':\n",
    "            word_class.append('isizulu')\n",
    "        elif class_id  == 'xho':\n",
    "            word_class.append('isiXhosa')\n",
    "        elif class_id  == 'ven':\n",
    "            word_class.append('Tshivenda')\n",
    "        elif class_id  == 'tso':\n",
    "            word_class.append('Xitsonga')\n",
    "        elif class_id  == 'tsn':\n",
    "            word_class.append('Setswana')\n",
    "        elif class_id == 'ssw':\n",
    "            word_class.append('siSwati')\n",
    "        elif class_id  == 'sot':\n",
    "            word_class.append('Sesotho')\n",
    "        elif class_id == 'nso':\n",
    "            word_class.append('Sepedi')\n",
    "        elif class_id == 'nbl':\n",
    "            word_class.append('isiNdebele')\n",
    "        elif class_id == 'eng' :\n",
    "            word_class.append(' English')\n",
    "        else:\n",
    "            word_class.append('Afrikaans')\n",
    "    df['lang_id'] = word_class\n",
    "        \n",
    "    return df\n",
    "\n",
    "#saving a working copy of train dataset\n",
    "train_copy = class_convert(train_df)\n",
    "#saving a working copy of test dataset\n",
    "test_copy = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b49d1824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>isiXhosa</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>isiXhosa</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>English</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sepedi</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tshivenda</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lang_id                                               text\n",
       "0   isiXhosa  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
       "1   isiXhosa  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
       "2    English  the province of kwazulu-natal department of tr...\n",
       "3     Sepedi  o netefatša gore o ba file dilo ka moka tše le...\n",
       "4  Tshivenda  khomishini ya ndinganyiso ya mbeu yo ewa maana..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Veiwing the new edited first 5 rows of the train dataframe\n",
    "train_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edeeeec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afrikaans</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sepedi</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sesotho</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Setswana</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tshivenda</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Xitsonga</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>isiNdebele</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>isiXhosa</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>isizulu</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>siSwati</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lang_id  text\n",
       "0      English  3000\n",
       "1    Afrikaans  3000\n",
       "2       Sepedi  3000\n",
       "3      Sesotho  3000\n",
       "4     Setswana  3000\n",
       "5    Tshivenda  3000\n",
       "6     Xitsonga  3000\n",
       "7   isiNdebele  3000\n",
       "8     isiXhosa  3000\n",
       "9      isizulu  3000\n",
       "10     siSwati  3000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking message count grouped by sentiment\n",
    "sentiment_temp_table = train_copy.groupby('lang_id').count()['text'].reset_index().sort_values(by='text')\n",
    "sentiment_temp_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb82028",
   "metadata": {},
   "source": [
    "### Data engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e0018ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mmasepala, fa maemo a a kgethegileng a letlele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tshivhumbeo tshi fana na ngano dza vhathu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Winste op buitelandse valuta.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5677</th>\n",
       "      <td>5678</td>\n",
       "      <td>You mark your ballot in private.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5678</th>\n",
       "      <td>5679</td>\n",
       "      <td>Ge o ka kgetha ka bowena go se šomiše Mofani k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5679</th>\n",
       "      <td>5680</td>\n",
       "      <td>E Ka kopo etsa kgetho ya hao ka hloko, hobane ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5680</th>\n",
       "      <td>5681</td>\n",
       "      <td>TB ke bokudi ba PMB, mme Morero o tla lefella ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5681</th>\n",
       "      <td>5682</td>\n",
       "      <td>Vakatjhela iwebhusayidi yethu ku-www.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5682 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                               text\n",
       "0         1  Mmasepala, fa maemo a a kgethegileng a letlele...\n",
       "1         2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
       "2         3         Tshivhumbeo tshi fana na ngano dza vhathu.\n",
       "3         4  Kube inja nelikati betingevakala kutsi titsini...\n",
       "4         5                      Winste op buitelandse valuta.\n",
       "...     ...                                                ...\n",
       "5677   5678                   You mark your ballot in private.\n",
       "5678   5679  Ge o ka kgetha ka bowena go se šomiše Mofani k...\n",
       "5679   5680  E Ka kopo etsa kgetho ya hao ka hloko, hobane ...\n",
       "5680   5681  TB ke bokudi ba PMB, mme Morero o tla lefella ...\n",
       "5681   5682              Vakatjhela iwebhusayidi yethu ku-www.\n",
       "\n",
       "[5682 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#function to replace all url links with the word 'url'\n",
    "def replace_tweet_urls(df, column_name):\n",
    "    \n",
    "    # Describing regrex url pattern\n",
    "    pattern_url = r'http[s]?://(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+'\n",
    "    \n",
    "    #substitute text to replace url\n",
    "    sub_url = r'url'\n",
    "    \n",
    "    df[column_name] = df[column_name].replace(to_replace = pattern_url,\n",
    "                            value = sub_url, \n",
    "                            regex = True) #train dataset\n",
    "    return df\n",
    "\n",
    "# Applying replace_tweet_urls function on both datasets replace all long urls with just 'url'  \n",
    "replace_tweet_urls(train_copy, 'text')\n",
    "replace_tweet_urls(test_copy, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "354079d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>isiXhosa</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>isiXhosa</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>English</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sepedi</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tshivenda</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lang_id                                               text\n",
       "0   isiXhosa  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
       "1   isiXhosa  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
       "2    English  the province of kwazulu-natal department of tr...\n",
       "3     Sepedi  o netefatša gore o ba file dilo ka moka tše le...\n",
       "4  Tshivenda  khomishini ya ndinganyiso ya mbeu yo ewa maana..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualising the cleaned columns\n",
    "train_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8e3e1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split Down sampled train dataset features into Predictors and Target \n",
    "X_sampled = train_copy['text']\n",
    "y_sampled = train_copy['lang_id']\n",
    "\n",
    "\n",
    "unseen_X = test_copy['text'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d57ab13",
   "metadata": {},
   "source": [
    "### Modelling and Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f637037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_trainer(model, X, y):\n",
    "    \n",
    "    \n",
    "    #\"\"\"create train model function\"\"\"\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=20)\n",
    "    \n",
    "    pipe = Pipeline([('vect', TfidfVectorizer(stop_words='english', \n",
    "                             min_df=1, \n",
    "                             max_df=0.9, \n",
    "                             ngram_range=(1, 3))),('tfidf', TfidfTransformer()),('model', model)])\n",
    "    \n",
    "    \n",
    "    \n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    f1_mscore = f1_score(y_test, y_pred, average='weighted')\n",
    "    accuracy_mscore = accuracy_score(y_test, y_pred)\n",
    "    recall_mscore = recall_score(y_test, y_pred, average='weighted')\n",
    "    precision_mscore = precision_score(y_test, y_pred, average='weighted')\n",
    "        \n",
    "       \n",
    "    print('Accuracy: ', accuracy_mscore)\n",
    "    print('f1_score: ', f1_mscore)\n",
    "    print('Recall: ', recall_mscore)\n",
    "    print('Precision: ', precision_mscore)\n",
    "    \n",
    "    metrics = {'Accuracy':accuracy_mscore, 'f1_score':f1_mscore, 'Recall': recall_mscore, 'Precision':precision_mscore}\n",
    "    #experiment.log_metrics(metrics)\n",
    "    #experiment.end()\n",
    "    return f1_mscore, accuracy_mscore, recall_mscore, precision_mscore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff5edfb",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "Below, we will calculate the metrics for each model.\n",
    "\n",
    "1. Logistic Regression\n",
    "Logistic regression is a classification algorithm used to predict the probability of an event occurring or belonging to a specific class. It's commonly used when the outcome variable is binary or categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "761a15b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an object of Logistic Regression\n",
    "log_regression = LogisticRegression(multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf33b454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.998030303030303\n",
      "f1_score:  0.9980309474183174\n",
      "Recall:  0.998030303030303\n",
      "Precision:  0.9980361311061432\n"
     ]
    }
   ],
   "source": [
    "imbalanced_lr_f1, imbalanced_lr_accuracy, imbalanced_lr_recall,\\\n",
    "imbalanced_lr_presicion = model_trainer(log_regression, X_sampled, y_sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4586f502",
   "metadata": {},
   "source": [
    "### 2. Decision Tree\n",
    "Decision trees are versatile classification algorithms that make predictions based on a series of if-else decisions. They are easy to interpret and can handle both categorical and numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b1610a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a decision tree classifier\n",
    "tree = DecisionTreeClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c95fa33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9240909090909091\n",
      "f1_score:  0.9231796767956224\n",
      "Recall:  0.9240909090909091\n",
      "Precision:  0.9240089441197742\n"
     ]
    }
   ],
   "source": [
    "imbalanced_tree_f1, imbalanced_tree_accuracy, imbalanced_tree_recall,\\\n",
    "imbalanced_tree_presicion = model_trainer(tree, X_sampled, y_sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e15d5e",
   "metadata": {},
   "source": [
    "### 3. Random Forest\n",
    "Random forests are an ensemble method that combines multiple decision trees to make more accurate predictions. They reduce overfitting and improve generalization by averaging the predictions of multiple trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3ff7f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an object of Random Forest\n",
    "forest = RandomForestClassifier(n_estimators=100, max_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d630cf14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8895454545454545\n",
      "f1_score:  0.9000113055751495\n",
      "Recall:  0.8895454545454545\n",
      "Precision:  0.9501562375534319\n"
     ]
    }
   ],
   "source": [
    "imbalanced_forest_f1, imbalanced_forest_accuracy, imbalanced_forest_recall,\\\n",
    "imbalanced_forest_presicion = model_trainer(forest, X_sampled, y_sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2421ecb0",
   "metadata": {},
   "source": [
    "### 4. Naive Bayes\n",
    "Multinomial Naive Bayes is a classification algorithm based on Bayes' theorem. It's commonly used for text classification problems, such as sentiment analysis or spam detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03e1ca84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an object of Naive Bayes\n",
    "naive_bayes = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5598d081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9995454545454545\n",
      "f1_score:  0.9995455723429163\n",
      "Recall:  0.9995454545454545\n",
      "Precision:  0.9995466822443402\n"
     ]
    }
   ],
   "source": [
    "imbalanced_naiveb_f1, imbalanced_naiveb_accuracy, imbalanced_naiveb_recall,\\\n",
    "imbalanced_naiveb_presicion = model_trainer(naive_bayes, X_sampled, y_sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c68de3b",
   "metadata": {},
   "source": [
    "Best Performing Model\n",
    "i have chosen the Multinomial Naive Bayes as my best performing model.\n",
    "\n",
    "Multinomial Naive Bayes has been widely used and studied in various natural language processing tasks, including sentiment analysis. It has demonstrated good performance in terms of accuracy and robustness, making it a popular choice in many text classification scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd91eb6",
   "metadata": {},
   "source": [
    "### Predict Function and Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a732c9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create predict function\n",
    "def test_target_predictor(model, X, y, test):\n",
    "    \n",
    "    pipe = Pipeline([('vect', TfidfVectorizer(stop_words='english', \n",
    "                             min_df=1, \n",
    "                             max_df=0.9, \n",
    "                             ngram_range=(1, 3))),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('model', model)])\n",
    "    \n",
    "    pipe.fit(X, y)\n",
    "    y_pred = pipe.predict(test)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff199dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mnb = test_target_predictor(naive_bayes, X_sampled, y_sampled, unseen_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24d0e600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Setswana', 'isiNdebele', 'Tshivenda', ..., 'Sesotho', 'Sesotho',\n",
       "       'isiNdebele'], dtype='<U10')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_mnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89690e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the kaggle submission Dataframe\n",
    "test = test_copy.set_index('index')\n",
    "final_test = test.index\n",
    "\n",
    "\n",
    "# Creating the Kaggle submission DataFrame without rounding\n",
    "final_dataframe = {'index': final_test, 'lang_id': y_pred_mnb}\n",
    "k_submission = pd.DataFrame(data=final_dataframe)\n",
    "k_submission = k_submission[['index', 'lang_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e68d8640",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_submission.to_csv('mnb.csv', index = False) #writing csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a685739",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/bolamash/classification/e11bc8cc59cb4bce999838bd8b0ea50f\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     C                               : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     alpha                           : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bootstrap                       : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     ccp_alpha                       : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     class_prior                     : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     class_weight                    : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     criterion                       : gini\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dual                            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fit_intercept                   : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fit_prior                       : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     intercept_scaling               : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     l1_ratio                        : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_depth                       : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_features                    : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_iter                        : 100\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_leaf_nodes                  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_samples                     : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     memory                          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     min_impurity_decrease           : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     min_samples_leaf                : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     min_samples_split               : 2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     min_weight_fraction_leaf        : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_C                         : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model__C                        : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model__alpha                    : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model__bootstrap                : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model__ccp_alpha                : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model__class_prior              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model__class_weight             : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model__criterion                : gini\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model__dual                     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model__fit_intercept            : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model__fit_prior                : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model__intercept_scaling        : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model__l1_ratio                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model__max_depth                : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model__max_features             : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model__max_iter                 : 100\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model__max_leaf_nodes           : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model__max_samples              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model__min_impurity_decrease    : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model__min_samples_leaf         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model__min_samples_split        : 2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model__min_weight_fraction_leaf : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model__multi_class              : ovr\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model__n_estimators             : 100\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model__n_jobs                   : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model__oob_score                : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model__penalty                  : l2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model__random_state             : 3\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model__solver                   : lbfgs\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model__splitter                 : best\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model__tol                      : 0.0001\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model__verbose                  : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model__warm_start               : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_alpha                     : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_bootstrap                 : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_ccp_alpha                 : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_class_prior               : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_class_weight              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_criterion                 : gini\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_dual                      : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_fit_intercept             : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_fit_prior                 : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_intercept_scaling         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_l1_ratio                  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_max_depth                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_max_features              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_max_iter                  : 100\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_max_leaf_nodes            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_max_samples               : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_min_impurity_decrease     : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_min_samples_leaf          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_min_samples_split         : 2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_min_weight_fraction_leaf  : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_multi_class               : ovr\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_n_estimators              : 100\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_n_jobs                    : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_oob_score                 : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_penalty                   : l2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_random_state              : 3\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_solver                    : lbfgs\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_splitter                  : best\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_tol                       : 0.0001\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_verbose                   : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_warm_start                : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     multi_class                     : ovr\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     n_estimators                    : 100\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     n_jobs                          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     neg_label                       : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     norm                            : l2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     oob_score                       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     penalty                         : l2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pos_label                       : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     random_state                    : 104\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     smooth_idf                      : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     solver                          : lbfgs\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     sparse_output                   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     splitter                        : best\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     sublinear_tf                    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf__norm                     : l2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf__smooth_idf               : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf__sublinear_tf             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf__use_idf                  : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf_norm                      : l2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf_smooth_idf                : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf_sublinear_tf              : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf_use_idf                   : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tol                             : 0.0001\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     use_idf                         : True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect__analyzer                  : word\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect__binary                    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect__decode_error              : strict\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect__dtype                     : <class 'numpy.float64'>\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect__encoding                  : utf-8\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect__input                     : content\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect__lowercase                 : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect__max_df                    : 0.9\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect__max_features              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect__min_df                    : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect__ngram_range               : (1, 3)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect__norm                      : l2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect__preprocessor              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect__smooth_idf                : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect__stop_words                : english\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect__strip_accents             : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect__sublinear_tf              : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect__token_pattern             : (?u)\\b\\w\\w+\\b\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect__tokenizer                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect__use_idf                   : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect__vocabulary                : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect_analyzer                   : word\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect_binary                     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect_decode_error               : strict\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect_dtype                      : <class 'numpy.float64'>\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect_encoding                   : utf-8\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect_input                      : content\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect_lowercase                  : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect_max_df                     : 0.9\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect_max_features               : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect_min_df                     : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect_ngram_range                : (1, 3)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect_norm                       : l2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect_preprocessor               : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect_smooth_idf                 : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect_stop_words                 : english\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect_strip_accents              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect_sublinear_tf               : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect_token_pattern              : (?u)\\b\\w\\w+\\b\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect_tokenizer                  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect_use_idf                    : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vect_vocabulary                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     verbose                         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warm_start                      : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-environment-definition : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-info                   : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-specification          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                     : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages           : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                     : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code                  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for metadata to finish uploading (timeout is 3600 seconds)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Uploading 172 metrics, params and output messages\n"
     ]
    }
   ],
   "source": [
    "# To end all experiments for Comet\n",
    "experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac176d93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
